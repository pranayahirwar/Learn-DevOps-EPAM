# S3-Buckets in AWS

## Overview of topics

- Keywords ‚Üí A quick reference for words.
- Different use cases of S3 Bucket
- S3 Security
- S3 Website Hosting
- S3 Versioning
- S3 Access Logs
- S3 Replications
- S3 Storage Class
- S3 Lifecycle Rule
- S3 Object Lock (WORM) & Glacier Vault Lock
- AWS Snow Family & OpsHub
- S3 Bucket Shared Responsibility Model

---

### Keywords for reference

- Durability ‚Üí It means if we are saving something in S3 it will stay forever until we delete it and won‚Äôt get lost with time. (Actually we lose data as time passes) Eg. So lets say you have saved ‚Äú1,00,00,000‚Äù object in S3 with ‚Äú99.999999999%‚Äù durability so within a 10,000 year time span we could lose ‚Äú1 object‚Äù from bucket.
- Availability ‚Üí Eg. S3 provide 99.99% Availability which stats that, if we are using S3 for 1 year then S3 is allowed to shutdown for 53min.
- Scaling ‚Üí Increasing or Decreasing of capacity or performance
- Data-Sync ‚Üí It‚Äôs a kind of app/service/feature present in AWS Snow family devices which all data transfer between device and S3 bucket
- edge-computing (w.r.t Snow Family)- Any place where internet is not present (moving car, underground lab, airplane) and snow device is getting utilized for computing, storing information.

---

### S3 - PROBLEMs THEY SOLVE & SOME INTRESTING FACT

- S3 are INFINITE in storage. Till now no one has utilized it fully.
- S3 bucket support MFA deletion.
- To delete bucket first you need to empty whole bucket first
- It is one of the most popular service offered by AWS
- NASDAQ is storing 8-9 year of data as an Backup in S3 (Glacier)
- They can be used to host static website, which mean we don‚Äôt have to install webserver software like Nginx, apache2.
- S3 can scale its network traffic by default
- Big Data & data analytics can be performed directly on S3 without downloading.
- It support Versioning
- You can create by default 100 Bucket in one Account, but if you want more you can make a request.
- Disaster Recovery
- Bucket Policy can‚Äôt be more than 20KB
- They can store any kind of data like, (?)

---

### S3 SECURITY

Below are following ways in which we can secure objects in our S3 bucket although bucket are private by default (not accessible from the internet)

- User Based
    - IAM policies ‚Üí giving permission based on per/user or group or role.
- Encryption ‚Üí It means each object uploaded to S3 is encrypted, the key using which it is encrypted can be autogenerated or created by you.
- Resource Based
    - Bucket Policies ‚Üí used very often, when you are making objects(data) accessible to internet or AWS Cross-Account
    - Object Access Control List (ACL) ‚Üí Work at much finer level
    - Bucket Access Control list ‚Üí Less common in use. You can use ACLs to grant permissions to AWS accounts or groups. For example, you can give full access to another account by adding its `canonical ID`
        
        These are the basic type of permission which can be found while creating ACLs for object or Bucket.
        
        - **Read**: Allows grantee to list the objects in the bucket or read an object‚Äôs data
        - **Write**: Allows grantee to create, overwrite, and delete any object in the bucket
        - **Read ACP**: Allows grantee to read the bucket or object ACL
        - **Write ACP**: Allows grantee to write the bucket or object ACL
        - **Full Control**: Allows grantee to perform all of the above actions

```json
#Simple bucket policy to give public access.
{
  "Id": "StaticWebPolicy",
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "S3GetObjectAllow",
      "Action": [
        "s3:GetObject",
      ],
      "Effect": "Allow",
      "Resource": "arn:aws:s3:::bucket-name/*",
      "Principal": "*"
    }
  ]
}
```

[Practical‚Üí Creating Bucket Policy to access objects from internet.](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Practical%E2%86%92%20Creating%20Bucket%20Policy%20to%20access%20object.md)

---

### HOSTING A STATIC WEB-SITE

It is like GitHub page where you just have to upload your file in repository (in GitHub) or S3 (in aws), the you just have to enable Static Website Hosting.

[Practical - Hosting a static website](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Practical%20-%20Hosting%20a%20static%20website.md)

<aside>
üí° It is a good practice if you are hosting a website using bucket, so place only website related thing in bucket. Place index file at the root of the bucket (it means don‚Äôt place index.html inside some folder.)

</aside>

---

### S3 - VERSIONING

In simple term if you reupload the same file with same name, doesn‚Äôt matter information inside the file is changed or not, it will create a new version history (which mean all the files will be save in S3 without overwriting it)

![Untitled](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Untitled.png)

- If file1, file2, file3 are present in bucket and versioning is applied after uploading these file, their base version ID will be NULL
- When objects are deleted in which `versioning` is enabled, a `delete marker` will be placed over the object, but it doesn‚Äôt mean we cannot delete object PERMANENTLY.
- Once versioning is enabled we can‚Äôt revert back.

---

### S3 - SERVER ACCESS LOGGING

Storing access logs is just storing logs generated by S3 bucket in some other S3 bucket.

Why we need to store logs?

- who is logging in s3
- which object is getting retrieved over the internet by whom
- Is there someone trying to inject something without permission in s3, etc.

> To enable this, first you need to create another bucket which will store the access log, then enable access log feature in main bucket.
To find access log setting, navigate to `Properties tab` and scroll down.
> 
> 
> Also keep in mind, it usually take 1-3hr (only once when you first enabled access log setting.) so that logs can be collected
> 

---

### Bucket Replication (CRR & SRR)

**************CRR ‚Üí Cross Region Replication ‚Üí**************  When you are saving data in Mumbai (Asia Pacific region) and as an backup saving the same data in US East (N. Virginia)

************SRR (Same Region Replication) ‚Üí************ When you are saving data in Mumbai (Asia Pacific region) and want to store data in Tokyo (Asia Pacific region)

- Versioning need to enabled on both the buckets
- Its an Asynchronous replication - it will happen in background.
- We can also enable this replication between 2 different AWS Account with proper IAM permission

<aside>
üí° Object uploaded before enabling replication, wont get uploaded to destination bucket.

</aside>

Why we need it?

- CRR Use cases
    - If your user are present in different region
    - compliance with data protection regulations
- SRR Use case
    - Log collection
    - live replication b/w production and test environment.

[Lab - How to enable replication.](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Lab%20-%20How%20to%20enable%20replication.md)

---

### S3 Storage Class

Use Cases of each storage class

S3 Standard ‚Üí Frequent data access. Eg ‚Üí

S3 Standard-IA ‚Üí Infrequent Access Eg ‚Üí 

S3 One Zone-IA ‚Üí Your data will be present in one zone only. Eg. Mumbai-1a or Mumbai-1b or Mumbai-1c

S3 Intelligent Tiering ‚Üí object is moved b/w standard S3 and S3 standard IA based on access pattern.

S3 Glacier ‚Üí Used for storing archive data where you know, if you need this data then you can wait for at max 12hrs.

S3 Glacier Deep Archive ‚Üí Used for Archive, max data retrieval time 48hrs (although is not always it depend on data size and age.)

![Untitled](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Untitled%201.png)

Enabling lifecycle policy

Lifecycle policy is for automating movement of object from one storage class to another storage class. 

Eg. You collect 100GB data each month and from those 100GB only 30GB data is frequently access using this rule you can move rest 70GB data to Standard-IA class, again you can apply some rules which states object which are120Days old in Standard-IA class move to Glacier deep archive and finally after 1year delete data from deep archive. It depend on situations.

Navigate to `Management tab` their you can find it. You can read through the process it is fairly simple.

---

### S3 Object Lock (WORM) & Glacier Vault Lock

WORM = Write Once Read Many.

These are simple setting in Which restrict object deletion from bucket according to policy they need to enabled when creating a bucket, after bucket creating we cannot enable this setting.

This rule is soo 

---

### AWS Snow Family

Snow family offer two things

- Storage device to move data from on-prem to AWS facility
- Edge computing (Running computation or collecting data)
- We can also reserve this device for 1 to 3 years.

Reason why we need Snow Family

![Untitled](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Untitled%202.png)

<aside>
üí° Rule of thumb for using snow family, if it take more than week to transfer data then you can use snow family.

</aside>

Use cases of Snowcone (It can also work on battery)

- Collecting data from a remote research site that doesn't have reliable internet access and transporting it back to a data center for analysis.
- Providing computing power and storage for a scientific experiment in a location without reliable electricity or internet access, such as a jungle or desert.
- It can also fit on top of drone which can be used for monitoring drone data.

Snowball Edge for Storage 

Can be used for Antarctica expeditions in ships, if you opt for edge computing you can get EC2 and AWS Lambda in this device.

Snowball Edge compute optimized (80TB HDD) and Storage optimized (42TB HDD)

Snowball Edge for Edge Computing

Special snowball are also made for GPU intensive task like video processing or machine learning

52vCPU and 208 GiB of RAM  and 42TB (Compute optimized )

40vCPU and 80 GiB of RAM and 80TB  (Storage optimized)

Snow Mobile ‚Üí Its a truck which will transfer your data which can be ( 100PB = 10,00,00TBs ). So if you are transferring >10PB of data you should use this.

<aside>
üí° It comes with 24*7 Video surveillance & GPS

</aside>

![Untitled](S3-Buckets%20in%20AWS%20a5ecc366172641009878bca6f7f7844b/Untitled%203.png)

> For using snow device when it arrive we need to install OpsHub, its a GUI for transferring data and using EC2 or Lambda functions.
> 

---

### S3 SHARED RESPONSIBILITY MODEL

| WHAT AWS TAKE CARE OF | WHAT USER NEED TO TAKE CARE OF |
| --- | --- |
| Infrastructure (Security of your data, no downtime for data, Automatic replication based on bucket type) | S3 Versioning, Bucket Policies, S3 storage classes, Logging and Monitoring |
| Configuration and vulnerability analysis tests | Which key to use for encryption, default or user generated. |
| Compliance Validation | Data Encryption while transit to S3 bucket. |

---